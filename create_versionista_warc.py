from collections import Counter
from datetime import timezone
import email.utils
import hashlib
from http import HTTPStatus
import importlib.metadata
from io import BytesIO
from itertools import islice
import logging
from textwrap import dedent
import httpx
from tqdm import tqdm
from warcio import WARCWriter, StatusAndHeaders
import web_monitoring_db


logger = logging.getLogger()

# Headers known to have been generated by Versionista, and not sourced from the
# original captured request.
BAD_HEADERS = set([
    'age', 'date', 'vary', 'expires', 'x-cachee', 'connection', 'accept-ranges', 'cache-control', 'transfer-encoding'
])

GIGABYTE = 1024 * 1024 * 1024


class BadDataError(Exception):
    reason = 'Bad_data'
    version_id = ''

    def __init__(self, version_id, message=None, reason=None):
        self.version_id = version_id
        self.reason = reason or self.reason
        super().__init__(f'{message or self.reason} (version={version_id})')


class MissingBodyError(BadDataError):
    reason = 'Body_never_saved'


def format_datetime_http(time):
    # email.utils does not support the UTC object dateutil uses, so fix it.
    return email.utils.format_datetime(time.astimezone(timezone.utc), usegmt=True)


def format_datetime_iso(time):
    iso_time = time.isoformat()
    # Use compact representation for UTC
    if iso_time.endswith('+00:00'):
        no_tz_date = iso_time.split("+", 1)[0]
        iso_time = f'{no_tz_date}Z'
    return iso_time


def status_text(code):
    status = HTTPStatus(code)
    return f'{status.value} {status.phrase}'


def load_response_body(version):
    body_response = httpx.get(version['body_url'])
    if body_response.status_code == 404:
        raise MissingBodyError(version['uuid'])

    actual_hash = hashlib.sha256(body_response.content).hexdigest()
    if actual_hash != version['body_hash']:
        detail = f'  Expected: {version["body_hash"]}\n  Actual:   {actual_hash}'
        raise AssertionError(f'Saved body does not match expected hash for version {version["uuid"]}\n{detail}')

    return body_response.content


def create_version_records(warc, version):
    records = []
    version_id = version['uuid']
    capture_time = version["capture_time"]

    if version['status'] is None:
        raise BadDataError(version_id, reason='Missing_status')

    if version['body_url'] is None:
        raise MissingBodyError(version_id)

    history = [version['url']]
    if version['source_metadata'].get('redirects'):
        history.extend(version['source_metadata']['redirects'])

    final_url = history[-1]
    for index, url in enumerate(history):
        recorded_headers = { 'Date': format_datetime_http(capture_time) }
        if url == final_url:
            if version['media_type']:
                recorded_headers['Content-Type'] = version['media_type']
            if version['headers']:
                for key, value in version['headers'].items():
                    if key.lower() not in BAD_HEADERS:
                        recorded_headers[key] = value
            http_headers = StatusAndHeaders(status_text(version['status']), recorded_headers.items(), protocol='HTTP/1.1')
            # Note this needs to be an IO object, so if we have bytes, use io.BytesIO(bytes)
            payload = BytesIO(load_response_body(version))
        else:
            recorded_headers = { 'Date': format_datetime_http(capture_time) }
            recorded_headers['Location'] = history[index + 1]
            http_headers = StatusAndHeaders(status_text(302), recorded_headers.items(), protocol='HTTP/1.1')
            payload = None

        # FIXME: Consider using warcit's WARC-Source-URI for the Versionista URL
        record_id = f'<https://api.monitoring.envirodatagov.org/api/v0/versions/{version_id}/responses/{index}>'
        records.append(warc.create_warc_record(
            url,
            'response',
            payload=payload,
            http_headers=http_headers,
            warc_headers_dict={
                'WARC-Record-ID': record_id,
                'WARC-Date': format_datetime_iso(capture_time)
                # Use warcit-style `WARC-Source-URI` header to link either versionista URL or WMDB URL?
                # https://github.com/webrecorder/warcit#warc-structure-and-format
            }
        ))
        # FIXME: add a metadata record?
        # DCMI isVersionOf with page URL? https://www.dublincore.org/specifications/dublin-core/dcmi-terms/#http://purl.org/dc/terms/isVersionOf
        # Use `via`, `hopsFromSeed` to link redirects?
        # Use `fetchTimeMs` when we have it here (version.source_metadata.load_time)

    return records


# FIXME: implement rolling file writing based on `warc_size`.
def main(*, skip_errors=False, start=0, limit=0, name='versionista', gzip=True, warc_size=8 * GIGABYTE):
    logging.basicConfig(level=logging.WARNING)

    # The magic number here is the current count of Versionista records.
    expected_records = min(845_325, limit)

    chunk_size = min(1000, limit)
    db_client = web_monitoring_db.Client.from_env()

    skipped = Counter()

    filename = f'{name}.warc'
    if gzip:
        filename += '.gz'
    with open(filename, 'wb') as fh:
        writer = WARCWriter(fh, gzip=gzip, warc_version='1.1')

        # Lots more that should probably go here, see spec ยง10.1
        # https://iipc.github.io/warc-specifications/specifications/warc-format/warc-1.1-annotated/#example-of-warcinfo-record
        # Original acquisition via:
        # - https://github.com/edgi-govdata-archiving/versionista-outputter
        # - https://github.com/edgi-govdata-archiving/web-monitoring-versionista-scraper
        record = writer.create_warcinfo_record(filename, {
            # Or `import pkg_resources; pkg_resources.get_distribution('warcio').version
            'software': f'warcio/{importlib.metadata.version("warcio")}',
            'description': dedent("""\
                Test manually created WARC""").replace('\n', ' ')
        })
        writer.write_record(record)

        versions = db_client.get_versions(source_type='versionista', chunk_size=chunk_size)
        if limit:
            versions = islice(versions, start, limit)

        progress_bar = tqdm(versions, unit=' versions', total=expected_records)
        for version in progress_bar:
            try:
                for record in create_version_records(writer, version):
                    writer.write_record(record)
            except BadDataError as error:
                # logger.warning(str(error))
                progress_bar.write(f'WARNING: {error}')
                skipped[error.reason] += 1
            except Exception as error:
                # logger.error(f'Error processing version {version.get("uuid")}')
                # logger.exception(error)
                progress_bar.write(f'Error processing version {version.get("uuid")}: {error}')
                if not skip_errors:
                    return

    # FIXME: Add resource record with logs:
    # https://iipc.github.io/warc-specifications/guidelines/warc-implementation-guidelines/#use-of-resource-records-for-processing-information

    print(f'Skipped {skipped.total()} Versionista versions:')
    for reason, count in skipped.items():
        print(f'  {reason.ljust(25, ".")} {str(count).rjust(5)}')


if __name__ == '__main__':
    main(skip_errors=False, limit=10, name='edgi_wm_versionista', gzip=False)
